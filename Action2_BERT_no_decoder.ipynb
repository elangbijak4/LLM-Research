{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyODi3aOqOTmIHX+SaTDbv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elangbijak4/LLM-Research/blob/main/Action2_BERT_no_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "# Input prompt\n",
        "prompt = input(\"Masukkan prompt Anda: \")\n",
        "\n",
        "# Tokenize input text\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "# Forward pass through BERT model\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids)\n",
        "\n",
        "# Get pooled output (CLS token representation)\n",
        "pooled_output = outputs.pooler_output\n",
        "\n",
        "# Decode tokens back to words or sentence\n",
        "decoded_tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze())\n",
        "decoded_prompt = tokenizer.decode(input_ids.squeeze(), skip_special_tokens=True)\n",
        "\n",
        "print(\"\\nPrompt yang dimasukkan:\", prompt)\n",
        "print(\"Prompt setelah didecode:\", decoded_prompt)\n",
        "print(\"Token-token yang dimasukkan:\", decoded_tokens)\n",
        "print(\"Representasi token (pooled output) shape:\", pooled_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyVmEMLZO01K",
        "outputId": "7cd2471e-96a1-40c7-83cd-a6c328c1e208"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masukkan prompt Anda: Jelaskan bumi\n",
            "\n",
            "Prompt yang dimasukkan: Jelaskan bumi\n",
            "Prompt setelah didecode: jelaskan bumi\n",
            "Token-token yang dimasukkan: ['[CLS]', 'je', '##las', '##kan', 'bum', '##i', '[SEP]']\n",
            "Representasi token (pooled output) shape: torch.Size([1, 768])\n"
          ]
        }
      ]
    }
  ]
}